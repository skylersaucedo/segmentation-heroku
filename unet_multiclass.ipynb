{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2536,
     "status": "ok",
     "timestamp": 1660327076446,
     "user": {
      "displayName": "skyler saucedo",
      "userId": "09056566326120682591"
     },
     "user_tz": 300
    },
    "id": "YETzdBcnSglR",
    "outputId": "d0ba1207-cb34-4936-a066-a02d48b25af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "Num GPUs Available:  1\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "9/18 using UNET muliticlass image segmentation \n",
    "https://github.com/bnsreenu/python_for_image_processing_APEER/blob/master/tutorial120_applying_trained_unet_model_to_large_images.ipynb\n",
    "version for rtx3090\n",
    "NEED TO take white 10x10 px space into account\n",
    "\n",
    "9/22 - removed white space, optimized onehot encoding procedure\n",
    "\n",
    "9/28 - Trying 512x512 version\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "print(sys.version)\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "print(gpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"..\")\n",
    "#os.chdir(os. getcwd() + \"\\\\src\")\n",
    "#from c import ROOT_DIR\n",
    "\n",
    "ROOT_DIR = 'c:\\\\Users\\\\endle\\\\Desktop\\\\mseisML\\\\src'\n",
    "os.chdir(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add Drive for dataset\n",
    "\"\"\"\n",
    "# local\n",
    "\n",
    "ROOT_DIR = 'c:\\\\Users\\\\endle\\\\Desktop\\\\mseisML'\n",
    "\n",
    "mask_path = ROOT_DIR + \"\\\\MLdata_unconditioned_sept19\\\\masks\\\\\"\n",
    "image_path = ROOT_DIR + \"\\\\MLdata_unconditioned_sept19\\\\das\\\\\"\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images, if needed\n",
    "SIZE_X = 512 #128 \n",
    "SIZE_Y = 512 #128\n",
    "n_classes=3 #Number of classes for segmentation\n",
    "num_images = 2612  #Total 1600 available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmethods to one-hot encode data\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "methods to one-hot encode data\n",
    "\"\"\"\n",
    "\n",
    "# import math\n",
    "\n",
    "# no_data = str([0,0,0])\n",
    "# p_wave = str([100,0,0])\n",
    "# s_wave = str([0,0,100])\n",
    "\n",
    "# labels = {no_data:0, p_wave:1, s_wave:2}\n",
    "\n",
    "# COLORS = ((0,0,0), (100,0,0), (0,0,100))\n",
    "\n",
    "# def closest_color(rgb, COLORS):\n",
    "\n",
    "#     \"\"\" find closest color from dict\"\"\"\n",
    "#     r, g, b = rgb\n",
    "#     color_diffs = []\n",
    "#     for color in COLORS:\n",
    "#         cr, cg, cb = color\n",
    "#         color_diff = math.sqrt((r - cr)**2 + (g - cg)**2 + (b - cb)**2)\n",
    "#         color_diffs.append((color_diff, color))\n",
    "\n",
    "#     return min(color_diffs)[1]\n",
    "\n",
    "# def label_pixel(path, COLORS, labels):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     create mask with label values as pixel\n",
    "#     this make take some time...\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "#     #x = img_size\n",
    "\n",
    "#     #img = load_img(path, target_size=self.img_size, color_mode=\"rgb\")\n",
    "#     img = cv2.imread(path)\n",
    "#     #img = cv2.resize(img, img_size)\n",
    "\n",
    "#     x = np.shape(img)\n",
    "\n",
    "#     #print('shape of x, ', x)\n",
    "#     values = [str(list(img[i,j])) for i in range(x[0]) for j in range(x[1])]\n",
    "#     mask=list([0]*x[0]*x[1])\n",
    "\n",
    "\n",
    "#     for i, value in enumerate(values):\n",
    "\n",
    "#         value = value.replace('[','').replace(']','').split(',')\n",
    "#         value = (int(value[0]), int(value[1]), int(value[2]))   \n",
    "#         value = closest_color(value, COLORS)\n",
    "#         value = list(value)   \n",
    "#         value = '[' + str(value[0]) + ', ' + str(value[1]) + ', ' + str(value[2]) + ']'   \n",
    "#         mask[i]=labels[value]\n",
    "\n",
    "#     #print('shape of mask before reshape', np.shape(mask))\n",
    "#     #print('shape of mask after reshape', np.shape(np.asarray(mask).reshape(x[0],x[1])))\n",
    "\n",
    "#     return np.asarray(mask).reshape(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image_dataset (2612, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"updated image routine\"\"\"\n",
    "\n",
    "bordr = 11 # saved images have border from matplotlib that can't be removed before saving.\n",
    "\n",
    "image_names = glob.glob(image_path + \"*.png\")\n",
    "image_names.sort()\n",
    "image_names_subset = image_names[0:num_images]\n",
    "#images = [cv2.imread(image, 0) for image in image_names_subset]\n",
    "\n",
    "images = []\n",
    "\n",
    "for image in image_names_subset:\n",
    "\n",
    "    \n",
    "    x = cv2.imread(image)\n",
    "    x_n = x[0:x.shape[1]-bordr, bordr:x.shape[0]][:]\n",
    "    x_f = cv2.resize(x_n, (SIZE_X,SIZE_Y), 3, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "    # # for greyscale inputs\n",
    "    # x = cv2.imread(image, 0)\n",
    "    # x_n = x[0:x.shape[1]-bordr, bordr:x.shape[0]]\n",
    "    # x_f = cv2.resize(x_n, (SIZE_X,SIZE_Y), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    images.append(x_f)\n",
    "\n",
    "image_dataset = np.array(images)\n",
    "#image_dataset = np.expand_dims(image_dataset, axis = 3) #use for greyscale\n",
    "\n",
    "print('shape of image_dataset', np.shape(image_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of masks (2612, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"updated mask routine\"\"\"\n",
    "\n",
    "mask_names = glob.glob(mask_path + \"*.png\")\n",
    "mask_names.sort()\n",
    "mask_names_subset = mask_names[0:num_images]\n",
    "\n",
    "masks = []\n",
    "\n",
    "for mask in mask_names_subset:\n",
    "\n",
    "    #do\n",
    "    # Load the image and obtain tensor with one-hot values\n",
    "\n",
    "    image = cv2.imread(mask)\n",
    "\n",
    "    # collapse on color\n",
    "\n",
    "    one_hot = np.asarray(np.round((1/255)*image[:,:,0])  + 2*np.round((1/255)*image[:,:,2]), dtype=np.int32)\n",
    "\n",
    "    # remove white border\n",
    "\n",
    "    one_hot = one_hot[0:one_hot.shape[1]-bordr, bordr:one_hot.shape[0]]\n",
    "\n",
    "    # resize\n",
    "\n",
    "    one_hot_c = cv2.resize(one_hot, (SIZE_X,SIZE_Y), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    masks.append(one_hot_c)\n",
    "\n",
    "\n",
    "print('shape of masks', np.shape(masks))\n",
    "\n",
    "mask_dataset = np.array(masks) # should be: shape of masks (2612, 128, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### old routine, it is slow.. delete later\n",
    "\n",
    "# # mask_names = glob.glob(mask_path + \"*.png\")\n",
    "# # mask_names.sort()\n",
    "# # mask_names_subset = mask_names[0:num_images]\n",
    "# # masks = [cv2.imread(mask, 0) for mask in mask_names_subset]\n",
    "# # mask_dataset = np.array(masks)\n",
    "\n",
    "# mask_names = glob.glob(mask_path + \"*.png\")\n",
    "# mask_names.sort()\n",
    "# mask_names_subset = mask_names[0:num_images]\n",
    "\n",
    "# #print('subset, ', mask_names_subset) # prints out\n",
    "\n",
    "# #convert masks from 3 channel into one hot encoding per pixel\n",
    "# #masks = [cv2.imread(mask, 0) for mask in mask_names_subset]\n",
    "\n",
    "# masks = []\n",
    "\n",
    "# for mask in mask_names_subset:\n",
    "#     y = label_pixel(mask, COLORS, labels)\n",
    "#     #print('shape of y:', np.shape(y))\n",
    "#     #plt.imshow(y)\n",
    "#     #cax = plt.axes([0.85, 0.1, 0.075, 0.8])\n",
    "#     #plt.colorbar(cax=cax)\n",
    "#     #plt.show()\n",
    "\n",
    "\n",
    "#     #fig, axs = plt.subplots(1,2, figsize=(9, 3), sharey=True)\n",
    "#     #axs[0].imshow(y)\n",
    "    \n",
    "#     y_n = y[0:y.shape[1]-10, 10:y.shape[0]]\n",
    "    \n",
    "#     y_f = cv2.resize(y_n, (SIZE_X,SIZE_Y), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "#     masks.append(y_f)\n",
    "\n",
    "# print('shape of masks', np.shape(masks))\n",
    "\n",
    "# mask_dataset = np.array(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape is:  (2612, 512, 512, 3)\n",
      "Mask data shape is:  (2612, 512, 512)\n",
      "Max pixel value in image is:  255\n",
      "Labels in the mask are :  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Image data shape is: \", image_dataset.shape)\n",
    "print(\"Mask data shape is: \", mask_dataset.shape)\n",
    "print(\"Max pixel value in image is: \", image_dataset.max())\n",
    "print(\"Labels in the mask are : \", np.unique(mask_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\endle\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode labels to 0, 1, 2, 3, ... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = mask_dataset.shape  \n",
    "mask_dataset_reshaped = mask_dataset.reshape(-1,1)\n",
    "mask_dataset_reshaped_encoded = labelencoder.fit_transform(mask_dataset_reshaped)\n",
    "mask_dataset_encoded = mask_dataset_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(mask_dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2612, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "mask_dataset_encoded = np.expand_dims(mask_dataset_encoded, axis = 3)\n",
    "print(mask_dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize images\n",
    "image_dataset = image_dataset /255.  #Can also normalize or scale using MinMax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset_encoded, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2089, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Updated UNET model, 512x512\n",
    "\"\"\"\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building Unet by dividing encoder and decoder into blocks OLDER\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "# def conv_block(input, num_filters):\n",
    "#     x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "#     x = BatchNormalization()(x)   #Not in the original network. \n",
    "#     x = Activation(\"relu\")(x)\n",
    "\n",
    "#     x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "#     x = BatchNormalization()(x)  #Not in the original network\n",
    "#     x = Activation(\"relu\")(x)\n",
    "\n",
    "#     return x\n",
    "\n",
    "# #Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "\n",
    "# def encoder_block(input, num_filters):\n",
    "#     x = conv_block(input, num_filters)\n",
    "#     p = MaxPool2D((2, 2))(x)\n",
    "#     return x, p   \n",
    "\n",
    "# #Decoder block\n",
    "# #skip features gets input from encoder for concatenation\n",
    "\n",
    "# def decoder_block(input, skip_features, num_filters):\n",
    "#     x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "#     x = Concatenate()([x, skip_features])\n",
    "#     x = conv_block(x, num_filters)\n",
    "#     return x\n",
    "\n",
    "# #Build Unet using the blocks\n",
    "# def build_unet(input_shape, n_classes):\n",
    "#     inputs = Input(input_shape)\n",
    "\n",
    "#     s1, p1 = encoder_block(inputs, 64)\n",
    "#     s2, p2 = encoder_block(p1, 128)\n",
    "#     s3, p3 = encoder_block(p2, 256)\n",
    "#     s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "#     b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "#     d1 = decoder_block(b1, s4, 512)\n",
    "#     d2 = decoder_block(d1, s3, 256)\n",
    "#     d3 = decoder_block(d2, s2, 128)\n",
    "#     d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "#     if n_classes == 1:  #Binary\n",
    "#       activation = 'sigmoid'\n",
    "#     else:\n",
    "#       activation = 'softmax'\n",
    "\n",
    "#     outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
    "#     print(activation)\n",
    "\n",
    "#     model = Model(inputs, outputs, name=\"U-Net\")\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"just jaccard index for loss \"\"\"\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape,  (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "print('input shape, ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 256, 32  0           ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d (SeparableCon  (None, 256, 256, 64  2400       ['activation_1[0][0]']           \n",
      " v2D)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['separable_conv2d[0][0]']       \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (SeparableC  (None, 256, 256, 64  4736       ['activation_2[0][0]']           \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 256, 256, 64  256        ['separable_conv2d_1[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 64  2112        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 128, 128, 64  0           ['max_pooling2d[0][0]',          \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 64  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 128, 128, 12  8896       ['activation_3[0][0]']           \n",
      " onv2D)                         8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_2[0][0]']     \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 128, 128, 12  17664      ['activation_4[0][0]']           \n",
      " onv2D)                         8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 12  512        ['separable_conv2d_3[0][0]']     \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 128)  8320        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 64, 64, 128)  0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 128)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 64, 64, 256)  34176      ['activation_5[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 64, 64, 256)  68096      ['activation_6[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 256)  1024       ['separable_conv2d_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 256)  33024       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 256)  0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 32, 256)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 256)  590080     ['activation_7[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 256)  590080     ['activation_8[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0          ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 64, 64, 256)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  65792       ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 64, 64, 256)  0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64, 64, 256)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 128)  295040     ['activation_9[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_transpose_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 128)  147584     ['activation_10[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 128)  512        ['conv2d_transpose_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 25  0          ['add_3[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 12  0          ['batch_normalization_10[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 12  32896       ['up_sampling2d_3[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 128, 128, 12  0           ['up_sampling2d_2[0][0]',        \n",
      "                                8)                                'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 128, 128, 12  0           ['add_4[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 128, 128, 64  73792      ['activation_11[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 128, 128, 64  256        ['conv2d_transpose_4[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 128, 128, 64  36928      ['activation_12[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 128, 128, 64  256        ['conv2d_transpose_5[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 256, 256, 12  0          ['add_4[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 64  0          ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 64  8256        ['up_sampling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 256, 256, 64  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 256, 256, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 256, 256, 32  18464      ['activation_13[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 32  128        ['conv2d_transpose_6[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 256, 256, 32  9248       ['activation_14[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 256, 256, 32  128        ['conv2d_transpose_7[0][0]']     \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 512, 512, 64  0          ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 512, 512, 32  0          ['batch_normalization_14[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 512, 512, 32  2080        ['up_sampling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 512, 512, 32  0           ['up_sampling2d_6[0][0]',        \n",
      "                                )                                 'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 512, 512, 3)  867         ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,058,979\n",
      "Trainable params: 2,055,203\n",
      "Non-trainable params: 3,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = build_unet(input_shape, n_classes=n_classes)\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='adam', loss=[jacard_coef_loss], metrics=[jacard_coef])\n",
    "#model.summary()\n",
    "\n",
    "img_size = (512, 512)\n",
    "model = get_model(img_size, n_classes)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train (2089, 512, 512, 3)\n",
      "shape of y_train_cat (2089, 512, 512, 3)\n",
      "shape of X_test (523, 512, 512, 3)\n",
      "shape of y_test_cat (523, 512, 512, 3)\n",
      "Epoch 1/25\n",
      " 30/131 [=====>........................] - ETA: 1:00 - loss: 0.6633 - accuracy: 0.9269"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\endle\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\endle\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\endle\\AppData\\Local\\Temp\\ipykernel_13724\\215566431.py\", line 8, in <cell line: 8>\n      history = model.fit(X_train, y_train_cat,\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[16,64,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5443]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\endle\\Desktop\\mseisML\\notebooks\\unet_multiclass.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mshape of X_test\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mshape(X_test))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mshape of y_test_cat\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mshape(y_test_cat))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train_cat, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                     batch_size \u001b[39m=\u001b[39;49m \u001b[39m16\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_test, y_test_cat), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/endle/Desktop/mseisML/notebooks/unet_multiclass.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                     shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\endle\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\endle\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\endle\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\endle\\AppData\\Local\\Temp\\ipykernel_13724\\215566431.py\", line 8, in <cell line: 8>\n      history = model.fit(X_train, y_train_cat,\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"c:\\Users\\endle\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[16,64,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/conv2d_7/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5443]"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "print('shape of X_train', np.shape(X_train))\n",
    "print('shape of y_train_cat', np.shape(y_train_cat))\n",
    "print('shape of X_test', np.shape(X_test))\n",
    "print('shape of y_test_cat', np.shape(y_test_cat))\n",
    "\n",
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=epochs, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model for future use\n",
    "\n",
    "model_path = 'saved_model/UNET_512x512_25ep_sept28.hdf5'\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include IOU\n",
    "jacard = history.history['jacard_coef']\n",
    "jacard_val = history.history['val_jacard_coef']\n",
    "\n",
    "plt.plot(epochs, jacard, 'y', label='Training jacard')\n",
    "plt.plot(epochs, jacard_val, 'r', label='Validation jacard')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('jacard')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previously saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_index(A,B,height,width):\n",
    "    \"\"\"https://www.delftstack.com/howto/python/opencv-compare-images/\"\"\"\n",
    "    errorL2 = cv2.norm( A, B, cv2.NORM_L2 )\n",
    "    return 1 - errorL2 / ( height * width )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Look at results\"\"\"\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    #do\n",
    "    X_test_r  = np.reshape(X_test[0],(-1,128,128,1))\n",
    "    print('shape of reshaped', np.shape(X_test_r))\n",
    "\n",
    "    y_pred=model.predict(X_test_r)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(141)\n",
    "    plt.imshow(X_test[0])\n",
    "    plt.title('Testing Image')\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(y_test_cat[0])\n",
    "    plt.title('Ground truth')\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(y_pred[0])\n",
    "    plt.title('Prediction')\n",
    "\n",
    "    plt.subplot(144)\n",
    "    y_pred_argmax=np.argmax(y_pred, axis=3)\n",
    "    plt.imshow(y_pred_argmax[0])\n",
    "    plt.title('Argmax Prediction')\n",
    "\n",
    "    gt = y_test_cat[0]\n",
    "    pd = y_pred_argmax[0]\n",
    "\n",
    "    gt_g = cv2.cvtColor(gt, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    print('shapes', np.shape(gt), np.shape(pd))\n",
    "    print('shapes', np.shape(gt_g), np.shape(pd))\n",
    "    \n",
    "    diff = gt_g - pd\n",
    "    #s_index = similarity_index(gt_g, pd,IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(diff)\n",
    "\n",
    "    print('sum of diff, ', np.sum(diff))\n",
    "    plt.show()\n",
    "\n",
    "    #print('sim index: ', s_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
    "y_pred_argmax.shape\n",
    "\n",
    "print(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using built in keras function\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 3\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To calculate I0U for each class...\n",
    "# values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "# print(values)\n",
    "# class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "# class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "# class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "# #class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "# print(\"IoU for class1 is: \", class1_IoU)\n",
    "# print(\"IoU for class2 is: \", class2_IoU)\n",
    "# print(\"IoU for class3 is: \", class3_IoU)\n",
    "# #print(\"IoU for class4 is: \", class4_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction on 50 images\n",
    "import random\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    test_img_number = random.randint(0, len(X_test)-1)\n",
    "    test_img = X_test[test_img_number]\n",
    "    ground_truth=y_test_cat[test_img_number]\n",
    "\n",
    "    print('shape of test_img', np.shape(test_img))\n",
    "    print('shape of ground_truth', np.shape(ground_truth))\n",
    "\n",
    "    test_img_norm=test_img[:,:,0][:,:,None]\n",
    "    print('shape of test_img_norm', np.shape(test_img_norm))\n",
    "\n",
    "    test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "    print('shape of test_img_input', np.shape(test_img_input))\n",
    "\n",
    "    #prediction = (model.predict(test_img_input))\n",
    "    #prediction = (model.predict(test_img))\n",
    "\n",
    "    #x = test_img\n",
    "    #s=128\n",
    "    #x = x.reshape(1,s,s,3)\n",
    "    #x = x.reshape(s,s,3)\n",
    "\n",
    "    prediction = model.predict(test_img_input)\n",
    "\n",
    "    print('shape of prediction', np.shape(prediction))\n",
    "\n",
    "    #print(prediction[:,60])\n",
    "\n",
    "    predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "    print('shape of predicted_img', np.shape(predicted_img))\n",
    "\n",
    "    print(predicted_img[:,80])\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(test_img[:,:,0], cmap='jet')\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
    "    plt.subplot(233)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(predicted_img, cmap='jet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOLAMRrGL8hvyI4bEtQV1fA",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of HR_DAS.ipynb",
   "provenance": [
    {
     "file_id": "10YgV6c40Myk6qksWLEuDLjWVgXBe3Dul",
     "timestamp": 1660385661046
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "61a5cdd612acd348ec380fc652d2e55330224965c53fb7d48a2e98389f5c9df7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
